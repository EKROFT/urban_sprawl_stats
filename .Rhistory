mu_PI <- apply(mu,2,PI,0.97)
plot( d2$year , d2$doy , col=col.alpha(rangi2,0.3) , pch=16 )
shade( mu_PI , d2$year , col=col.alpha("black",0.5) )
###Chapter 5###############################
# load data and copy
library(rethinking)
data(WaffleDivorce)
d <- WaffleDivorce
# standardize variables
d$D <- standardize( d$Divorce )
d$M <- standardize( d$Marriage )
d$A <- standardize( d$MedianAgeMarriage )
sd( d$MedianAgeMarriage )
m5.1 <- quap(
alist(
D ~ dnorm( mu , sigma ) ,
mu <- a + bA * A ,
a ~ dnorm( 0 , 0.2 ) ,
bA ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) , data = d )
set.seed(10)
prior <- extract.prior( m5.1 )
mu <- link( m5.1 , post=prior , data=list( A=c(-2,2) ) )
plot( NULL , xlim=c(-2,2) , ylim=c(-2,2) )
for ( i in 1:50 ) lines( c(-2,2) , mu[i,] , col=col.alpha("black",0.4) )
# compute percentile interval of mean
A_seq <- seq( from=-3 , to=3.2 , length.out=30 )
mu <- link( m5.1 , data=list(A=A_seq) )
mu.mean <- apply( mu , 2, mean )
mu.PI <- apply( mu , 2 , PI )
# plot it all
plot( D ~ A , data=d , col=rangi2 )
lines( A_seq , mu.mean , lwd=2 )
shade( mu.PI , A_seq )
m5.2 <- quap(
alist(
D ~ dnorm( mu , sigma ) ,
mu <- a + bM * M ,
a ~ dnorm( 0 , 0.2 ) ,
bM ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) , data = d )
###Learning DAGs
library(dagitty)
dag5.1 <- dagitty( "dag{ A -> D; A -> M; M -> D }" )
coordinates(dag5.1) <- list( x=c(A=0,D=1,M=2) , y=c(A=0,D=1,M=0) )
drawdag( dag5.1 )
DMA_dag2 <- dagitty('dag{ D <- A -> M }')
impliedConditionalIndependencies( DMA_dag2 )
DMA_dag1 <- dagitty('dag{ D <- A -> M -> D }')
impliedConditionalIndependencies( DMA_dag1 )
impliedConditionalIndependencies( DMA_dag1 )
m5.3 <- quap(
alist(
D ~ dnorm( mu , sigma ) ,
mu <- a + bM*M + bA*A ,
a ~ dnorm( 0 , 0.2 ) ,
bM ~ dnorm( 0 , 0.5 ) ,
bA ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) , data = d )
precis( m5.3 )
plot( coeftab(m5.1,m5.2,m5.3), par=c("bA","bM") )
plot( coeftab(m5.1,m5.2,m5.3), par=c("bA","bM") )
N <- 50 # number of simulated States
age <- rnorm( N ) # sim A
mar <- rnorm( N , -age ) # sim A -> M
div <- rnorm( N , age ) # sim A -> D
m5.4 <- quap(
alist(
M ~ dnorm( mu , sigma ) ,
mu <- a + bAM * A ,
a ~ dnorm( 0 , 0.2 ) ,
bAM ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) , data = d )
mu <- link(m5.4)
mu_mean <- apply( mu , 2 , mean )
mu_resid <- d$M - mu_mean
# call link without specifying new data
# so it uses original data
mu <- link( m5.3 )
# summarize samples across cases
mu_mean <- apply( mu , 2 , mean )
mu_PI <- apply( mu , 2 , PI )
# simulate observations
# again no new data, so uses original data
D_sim <- sim( m5.3 , n=1e4 )
D_PI <- apply( D_sim , 2 , PI )
plot( mu_mean ~ d$D , col=rangi2 , ylim=range(mu_PI) ,
xlab="Observed divorce" , ylab="Predicted divorce" )
abline( a=0 , b=1 , lty=2 )
for ( i in 1:nrow(d) ) lines( rep(d$D[i],2) , mu_PI[,i] , col=rangi2 )
identify( x=d$D , y=mu_mean , labels=d$Loc )
data(WaffleDivorce)
d <- list()
d$A <- standardize( WaffleDivorce$MedianAgeMarriage )
d$D <- standardize( WaffleDivorce$Divorce )
d$M <- standardize( WaffleDivorce$Marriage )
m5.3_A <- quap(
alist(
## A -> D <- M
D ~ dnorm( mu , sigma ) ,
mu <- a + bM*M + bA*A ,
a ~ dnorm( 0 , 0.2 ) ,
bM ~ dnorm( 0 , 0.5 ) ,
bA ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 ),
## A -> M
M ~ dnorm( mu_M , sigma_M ),
mu_M <- aM + bAM*A,
aM ~ dnorm( 0 , 0.2 ),
bAM ~ dnorm( 0 , 0.5 ),
sigma_M ~ dexp( 1 )
) , data = d )
precis(m5.3_A)
A_seq <- seq( from=-2 , to=2 , length.out=30 )
# prep data
sim_dat <- data.frame( A=A_seq )
# simulate M and then D, using A_seq
s <- sim( m5.3_A , data=sim_dat , vars=c("M","D") )
lot( sim_dat$A , colMeans(s$D) , ylim=c(-2,2) , type="l" ,
xlab="manipulated A" , ylab="counterfactual D" )
shade( apply(s$D,2,PI) , sim_dat$A )
mtext( "Total counterfactual effect of A on D" )
# prep data
sim_dat <- data.frame( A=A_seq )
# simulate M and then D, using A_seq
s <- sim( m5.3_A , data=sim_dat , vars=c("M","D") )
lot( sim_dat$A , colMeans(s$D) , ylim=c(-2,2) , type="l" ,
xlab="manipulated A" , ylab="counterfactual D" )
shade( apply(s$D,2,PI) , sim_dat$A )
mtext( "Total counterfactual effect of A on D" )
sim2_dat <- data.frame( A=(c(20,30)-26.1)/1.24 )
s2 <- sim( m5.3_A , data=sim2_dat , vars=c("M","D") )
mean( s2$D[,2] - s2$D[,1] )
sim_dat <- data.frame( M=seq(from=-2,to=2,length.out=30) , A=0 )
s <- sim( m5.3_A , data=sim_dat , vars="D" )
plot( sim_dat$M , colMeans(s) , ylim=c(-2,2) , type="l" ,
xlab="manipulated M" , ylab="counterfactual D" )
shade( apply(s,2,PI) , sim_dat$M )
mtext( "Total counterfactual effect of M on D" )
set.seed(1914)
N <- 200 # num grant proposals
p <- 0.1 # proportion to select
# uncorrelated newsworthiness and trustworthiness
nw <- rnorm(N)
tw <- rnorm(N)
# select top 10% of combined scores
s <- nw + tw # total score
q <- quantile( s , 1-p ) # top 10% threshold
selected <- ifelse( s >= q , TRUE , FALSE )
cor( tw[selected] , nw[selected] )
N <- 100 # number of individuals
set.seed(909)
height <- rnorm(N,10,2) # sim total height of each
leg_prop <- runif(N,0.4,0.5) # leg as proportion of height
leg_left <- leg_prop*height + # sim left leg as proportion + error
rnorm( N , 0 , 0.02 )
leg_right <- leg_prop*height + # sim right leg as proportion + error
rnorm( N , 0 , 0.02 )
# combine into data frame
d <- data.frame(height,leg_left,leg_right)
m6.1 <- quap(
alist(
height ~ dnorm( mu , sigma ) ,
mu <- a + bl*leg_left + br*leg_right ,
a ~ dnorm( 10 , 100 ) ,
bl ~ dnorm( 2 , 10 ) ,
br ~ dnorm( 2 , 10 ) ,
sigma ~ dexp( 1 )
) , data=d )
precis(m6.1)
##Learning quadratic approximation##############
library(rethinking)
m6.1 <- quap(
alist(
height ~ dnorm( mu , sigma ) ,
mu <- a + bl*leg_left + br*leg_right ,
a ~ dnorm( 10 , 100 ) ,
bl ~ dnorm( 2 , 10 ) ,
br ~ dnorm( 2 , 10 ) ,
sigma ~ dexp( 1 )
) , data=d )
precis(m6.1)
post <- extract.samples(m6.1)
plot( bl ~ br , post , col=col.alpha(rangi2,0.1) , pch=16 )
sum_blbr <- post$bl + post$br
dens( sum_blbr , col=rangi2 , lwd=2 , xlab="sum of bl and br" )
m6.2 <- quap(
alist(
height ~ dnorm( mu , sigma ) ,
mu <- a + bl*leg_left,
a ~ dnorm( 10 , 100 ) ,
bl ~ dnorm( 2 , 10 ) ,
sigma ~ dexp( 1 )
) , data=d )
precis(m6.2)
data(milk)
d <- milk
d$K <- standardize( d$kcal.per.g )
d$F <- standardize( d$perc.fat )
d$L <- standardize( d$perc.lactose )
m6.3 <- quap(
alist(
K ~ dnorm( mu , sigma ) ,
mu <- a + bF*F ,
a ~ dnorm( 0 , 0.2 ) ,
bF ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) , data=d )
# kcal.per.g regressed on perc.lactose
m6.4 <- quap(
alist(
K ~ dnorm( mu , sigma ) ,
mu <- a + bL*L ,
a ~ dnorm( 0 , 0.2 ) ,
bL ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) , data=d )
precis( m6.3 )
precis( m6.4 )
m6.5 <- quap(
alist(
K ~ dnorm( mu , sigma ) ,
mu <- a + bF*F + bL*L ,
a ~ dnorm( 0 , 0.2 ) ,
bF ~ dnorm( 0 , 0.5 ) ,
bL ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) ,
data=d )
precis( m6.5 )
pairs( ~ kcal.per.g + perc.fat + perc.lactose , data=d , col=rangi2 )
set.seed(71)
# number of plants
N <- 100
# simulate initial heights
h0 <- rnorm(N,10,2)
# assign treatments and simulate fungus and growth
treatment <- rep( 0:1 , each=N/2 )
fungus <- rbinom( N , size=1 , prob=0.5 - treatment*0.4 )
h1 <- h0 + rnorm(N, 5 - 3*fungus)
# compose a clean data frame
d <- data.frame( h0=h0 , h1=h1 , treatment=treatment , fungus=fungus )
sim_p <- rlnorm( 1e4 , 0 , 0.25 )
precis( data.frame(sim_p) )
sim_p <- rlnorm( 1e4 , 0 , 0.25 )
precis( data.frame(sim_p) )
m6.6 <- quap(
alist(
h1 ~ dnorm( mu , sigma ),
mu <- h0*p,
p ~ dlnorm( 0 , 0.25 ),
sigma ~ dexp( 1 )
), data=d )
precis(m6.6)
m6.7 <- quap(
alist(
h1 ~ dnorm( mu , sigma ),
mu <- h0 * p,
p <- a + bt*treatment + bf*fungus,
a ~ dlnorm( 0 , 0.2 ) ,
bt ~ dnorm( 0 , 0.5 ),
bf ~ dnorm( 0 , 0.5 ),
sigma ~ dexp( 1 )
), data=d )
precis(m6.7)
m6.8 <- quap(
alist(
h1 ~ dnorm( mu , sigma ),
mu <- h0 * p,
p <- a + bt*treatment,
a ~ dlnorm( 0 , 0.2 ),
bt ~ dnorm( 0 , 0.5 ),
sigma ~ dexp( 1 )
), data=d )
precis(m6.8)
library(dagitty)
plant_dag <- dagitty( "dag {
H_0 -> H_1
F -> H_1
T -> F
}")
coordinates( plant_dag ) <- list( x=c(H_0=0,T=2,F=1.5,H_1=1) ,
y=c(H_0=0,T=0,F=0,H_1=0) )
drawdag( plant_dag )
impliedConditionalIndependencies(plant_dag)
set.seed(71)
N <- 1000
h0 <- rnorm(N,10,2)
treatment <- rep( 0:1 , each=N/2 )
M <- rbern(N)
fungus <- rbinom( N , size=1 , prob=0.5 - treatment*0.4 + 0.4*M )
h1 <- h0 + rnorm( N , 5 + 3*M )
d2 <- data.frame( h0=h0 , h1=h1 , treatment=treatment , fungus=fungus )
library(rethinking)
d <- sim_happiness( seed=1977 , N_years=1000 )
precis(d)
d2 <- d[ d$age>17 , ] # only adults
d2$A <- ( d2$age - 18 ) / ( 65 - 18 )
d2$mid <- d2$married + 1
m6.9 <- quap(
alist(
happiness ~ dnorm( mu , sigma ),
mu <- a[mid] + bA*A,
a[mid] ~ dnorm( 0 , 1 ),
bA ~ dnorm( 0 , 2 ),
sigma ~ dexp(1)
) , data=d2 )
precis(m6.9,depth=2)
m6.10 <- quap(
alist(
happiness ~ dnorm( mu , sigma ),
mu <- a + bA*A,
a ~ dnorm( 0 , 1 ),
bA ~ dnorm( 0 , 2 ),
sigma ~ dexp(1)
) , data=d2 )
precis(m6.10)
N <- 200 # number of grandparent-parent-child triads
b_GP <- 1 # direct effect of G on P
b_GC <- 0 # direct effect of G on C
b_PC <- 1 # direct effect of P on C
b_U <- 2 # direct effect of U on P and C
set.seed(1)
U <- 2*rbern( N , 0.5 ) - 1
G <- rnorm( N )
P <- rnorm( N , b_GP*G + b_U*U )
C <- rnorm( N , b_PC*P + b_GC*G + b_U*U )
d <- data.frame( C=C , P=P , G=G , U=U )
m6.11 <- quap(
alist(
C ~ dnorm( mu , sigma ),
mu <- a + b_PC*P + b_GC*G,
a ~ dnorm( 0 , 1 ),
c(b_PC,b_GC) ~ dnorm( 0 , 1 ),
sigma ~ dexp( 1 )
), data=d )
precis(m6.11)
m6.12 <- quap(
alist(
C ~ dnorm( mu , sigma ),
mu <- a + b_PC*P + b_GC*G + b_U*U,
a ~ dnorm( 0 , 1 ),
c(b_PC,b_GC,b_U) ~ dnorm( 0 , 1 ),
sigma ~ dexp( 1 )
), data=d )
precis(m6.12)
library(dagitty)
dag_6.1 <- dagitty( "dag {
U [unobserved]
X -> Y
X <- U <- A -> C -> Y
U -> B <- C
}")
adjustmentSets( dag_6.1 , exposure="X" , outcome="Y" )
data<-read.csv("Data/shortlist_data_0813.csv")
library(ggplot2)
library(stringr)
library(tidyverse)
library(viridis)
my.theme<-theme(axis.title = element_text(size=12),
legend.title=element_text(size=12),
legend.text = element_text(size=10))
setwd("~/")
yard.data<-read.csv("Data/compiled_data_0813.csv")
library(tidyverse)
library(ggplot2)
fil<-filter(yard.data, "Households">0)
plot(BY_Ratio~BD, data=yard.data)
setwd("~/Masters/Maps and Data/urban_sprawl_stats")
no2.data<-read.csv("Data/compiled_data_0203.csv")
library(tidyverse)
##Testing GAM models
library(mgcv)
library(nlme)
library(gstat)
library(sp)
library(ape)
##trying spatial plus approach
BD_gam<- gam(BD~s(Lat*Long), data=no2.data)
resid_BD<-residuals(BD_gam)
income_gam<-gam(log(Income)~s(Lat*Long), data=no2.data, na.action=na.exclude)
resid_income<-residuals(income_gam)
road_gam<-gam(log(road.distance..meters.)~s(Lat*Long), data=no2.data)
resid_road<-residuals(road_gam)
canopy_gam<-gam(X.canopy~s(Lat*Long), data=no2.data)
resid_canopy<-residuals(canopy_gam)
no2.gam11<-gam(NO2_mean~resid_BD+resid_income+resid_road+resid_canopy+s(Lat,Long), data=no2.data,
method="REML")
summary(no2.gam11)
gam.check(no2.gam11)
concurvity(no2.gam11)
Boroughs<-as.factor(no2.data$Borough)
##trying borough as random effect
no2.gam12<-gam(NO2_mean~s(BD)+s(Income)+s(road.distance..meters.)+s(X.canopy)+
s(Boroughs, bs="re"), data=no2.data, method="REML", na.action=na.exclude)
summary(no2.gam12)
library(qpcR)
values1<-AIC(no2.gam11, no2.gam12)
akaike.weights(values1)
values1
##trying both approaches together
no2.gam13<-gam(NO2_mean~resid_BD+resid_income+resid_road+resid_canopy
+s(Lat,Long)+s(Boroughs, bs="re"), data=no2.data,
method="REML")
values1<-AIC(no2.gam11, no2.gam12, no2.gam13)
akaike.weights(values1)
values1
anova(no2.gam11, no2.gam13)
anova(no2.gam11, no2.gam13, method="Chisq")
##households as GAM
House_gam<- gam(Households~s(Lat*Long), data=fil)
fil<-filter(no2.data, Households>0)
##households as GAM
House_gam<- gam(Households~s(Lat*Long), data=fil)
resid_House<-residuals(House_gam)
BD_gam<- gam(BD~s(Lat*Long), data=fil)
resid_BD<-residuals(BD_gam)
no2.gam.house<-gam(NO2_mean~s(resid_House)+s(resid_BD)+s(Lat,Long), data=fil,
method="REML")
summary(no2.gam.house)
gam.check(no2.gam.house)
##Looking at alternative dates
no2.alt<-read.csv("Data/NO2_alternativedates.csv")
BD_gam<- gam(BD~s(Lat*Long), data=no2.alt)
resid_BD<-residuals(BD_gam)
income_gam<-gam(log(Income)~s(Lat*Long), data=no2.alt, na.action=na.exclude)
resid_income<-residuals(income_gam)
road_gam<-gam(log(road.distance..meters.)~s(Lat*Long), data=no2.alt)
resid_road<-residuals(road_gam)
canopy_gam<-gam(X.canopy~s(Lat*Long), data=no2.alt)
resid_canopy<-residuals(canopy_gam)
no2.gamalt<-gam(MayNO2_mean~resid_BD+resid_income+resid_road+resid_canopy+s(Lat,Long), data=no2.alt,
method="REML")
summary(no2.gamalt)
summary(no2.gam11)
gs.data<-read.csv("Data/compiled_data_0324.csv")
fil<-filter(gs.data, Households>0)
library(mgcv)
##Trying household relationship as a GAM
Boroughs<-as.factor(fil$Borough)
gam.gs<-gam(Man_GS~s(Households)+s(BD)s(Boroughs, bs="re"), data=fil, method="REML")
gam.gs<-gam(Man_GS~s(Households)+s(BD)+s(Boroughs, bs="re"), data=fil, method="REML")
summary(gam.gs)
gam.check(gam.gs)
plot(gam.gs)
plot(Man_GS~Households, data=fil, pch=16)
gam.gs2<-gam(Man_GS~s(BD)+s(Income), data=gs.data)
summary(gam.gs2)
model = gam(Man_GS ~ s(BD)+s(Income, na.action=na.exclude)+s(Boroughs, bs="re"),
data=gs.data,
method="REML")
model = gam(Man_GS ~ s(BD)+s(Income)+s(Boroughs, bs="re"),
data=gs.data, na.action=na.exclude,
method="REML")
model = gam(Man_GS ~ s(BD)+s(Income)+s(Borough, bs="re"),
data=gs.data, na.action=na.exclude,
method="REML")
##Trying household relationship as a GAM
Boroughs<-as.factor(fil$Borough)
model = gam(Man_GS ~ s(BD)+s(Income)+s(Boroughs, bs="re"),
data=gs.data, na.action=na.exclude,
method="REML")
model = gam(Man_GS ~ s(BD)+s(Income)+s(Boroughs, bs="re"),
data=gs.data, na.action=na.exclude)
model<-gam(Man_GS ~ s(BD)+s(Income)+s(Boroughs, bs="re"),
data=gs.data, na.action=na.exclude)
model<-gam(Man_GS ~ s(BD)+s(Income)+s(Boroughs, bs="re"),
data=gs.data, method="REML",na.action=na.exclude)
model<-gam(Man_GS ~ s(BD)+s(Boroughs, bs="re"),
data=gs.data, method="REML",na.action=na.exclude)
##trying borough as random effect
no2.gam12<-gam(NO2_mean~s(BD)+s(Income)+s(road.distance..meters.)+s(X.canopy)+
s(Boroughs, bs="re"), data=no2.data, method="REML", na.action=na.exclude)
gs.data<-read.csv("Data/compiled_data_0324.csv")
##Trying household relationship as a GAM
Boroughs<-as.factor(fil$Borough)
Boroughs<-as.factor(gs.data$Borough)
model<-gam(Man_GS ~ s(BD)+s(Income)+s(Boroughs, bs="re"),
data=gs.data, method="REML",na.action=na.exclude)
library(car)
model.fixed<-gam(Man_GS~s(BD)+s(Income), data=gs.data, method="REML", na.action=na.exclude)
anova(model,model.fixed)
library(qpcR)
values<-AIC(model, model.fixed)
akaike.weights(values)
values
anova(model,model.fixed)
summary(model)
summary(model.fixed)
##Trying household relationship as a GAM
Boroughs<-as.factor(fil$Borough)
gam.gs<-gam(Man_GS~s(Households)+s(BD)+s(Boroughs, bs="re"), data=fil, method="REML")
summary(gam.gs)
gam.check(gam.gs)
plot(gam.gs)
gam.gs2<-gam(Man_GS~s(Households)+s(BD), data=fil, method="REML")
values2<-AIC(gam.gs, gam.gs2)
values2
akaike.weights(values2)
##households as GAM
House_gam<- gam(Households~s(Lat*Long), data=fil)
resid_House<-residuals(House_gam)
BD_gam<- gam(BD~s(Lat*Long), data=fil)
resid_BD<-residuals(BD_gam)
no2.gam.house<-gam(NO2_mean~s(resid_House)+s(resid_BD)+s(Lat,Long), data=fil,
method="REML")
summary(no2.gam.house)
gam.check(no2.gam.house)
