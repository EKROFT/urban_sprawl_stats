alist(
M ~ dnorm( mu , sigma ) ,
mu <- a + bAM * A ,
a ~ dnorm( 0 , 0.2 ) ,
bAM ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) , data = d )
mu <- link(m5.4)
mu_mean <- apply( mu , 2 , mean )
mu_resid <- d$M - mu_mean
# call link without specifying new data
# so it uses original data
mu <- link( m5.3 )
# summarize samples across cases
mu_mean <- apply( mu , 2 , mean )
mu_PI <- apply( mu , 2 , PI )
# simulate observations
# again no new data, so uses original data
D_sim <- sim( m5.3 , n=1e4 )
D_PI <- apply( D_sim , 2 , PI )
plot( mu_mean ~ d$D , col=rangi2 , ylim=range(mu_PI) ,
xlab="Observed divorce" , ylab="Predicted divorce" )
abline( a=0 , b=1 , lty=2 )
for ( i in 1:nrow(d) ) lines( rep(d$D[i],2) , mu_PI[,i] , col=rangi2 )
identify( x=d$D , y=mu_mean , labels=d$Loc )
data(WaffleDivorce)
d <- list()
d$A <- standardize( WaffleDivorce$MedianAgeMarriage )
d$D <- standardize( WaffleDivorce$Divorce )
d$M <- standardize( WaffleDivorce$Marriage )
m5.3_A <- quap(
alist(
## A -> D <- M
D ~ dnorm( mu , sigma ) ,
mu <- a + bM*M + bA*A ,
a ~ dnorm( 0 , 0.2 ) ,
bM ~ dnorm( 0 , 0.5 ) ,
bA ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 ),
## A -> M
M ~ dnorm( mu_M , sigma_M ),
mu_M <- aM + bAM*A,
aM ~ dnorm( 0 , 0.2 ),
bAM ~ dnorm( 0 , 0.5 ),
sigma_M ~ dexp( 1 )
) , data = d )
precis(m5.3_A)
A_seq <- seq( from=-2 , to=2 , length.out=30 )
# prep data
sim_dat <- data.frame( A=A_seq )
# simulate M and then D, using A_seq
s <- sim( m5.3_A , data=sim_dat , vars=c("M","D") )
lot( sim_dat$A , colMeans(s$D) , ylim=c(-2,2) , type="l" ,
xlab="manipulated A" , ylab="counterfactual D" )
shade( apply(s$D,2,PI) , sim_dat$A )
mtext( "Total counterfactual effect of A on D" )
# prep data
sim_dat <- data.frame( A=A_seq )
# simulate M and then D, using A_seq
s <- sim( m5.3_A , data=sim_dat , vars=c("M","D") )
lot( sim_dat$A , colMeans(s$D) , ylim=c(-2,2) , type="l" ,
xlab="manipulated A" , ylab="counterfactual D" )
shade( apply(s$D,2,PI) , sim_dat$A )
mtext( "Total counterfactual effect of A on D" )
sim2_dat <- data.frame( A=(c(20,30)-26.1)/1.24 )
s2 <- sim( m5.3_A , data=sim2_dat , vars=c("M","D") )
mean( s2$D[,2] - s2$D[,1] )
sim_dat <- data.frame( M=seq(from=-2,to=2,length.out=30) , A=0 )
s <- sim( m5.3_A , data=sim_dat , vars="D" )
plot( sim_dat$M , colMeans(s) , ylim=c(-2,2) , type="l" ,
xlab="manipulated M" , ylab="counterfactual D" )
shade( apply(s,2,PI) , sim_dat$M )
mtext( "Total counterfactual effect of M on D" )
set.seed(1914)
N <- 200 # num grant proposals
p <- 0.1 # proportion to select
# uncorrelated newsworthiness and trustworthiness
nw <- rnorm(N)
tw <- rnorm(N)
# select top 10% of combined scores
s <- nw + tw # total score
q <- quantile( s , 1-p ) # top 10% threshold
selected <- ifelse( s >= q , TRUE , FALSE )
cor( tw[selected] , nw[selected] )
N <- 100 # number of individuals
set.seed(909)
height <- rnorm(N,10,2) # sim total height of each
leg_prop <- runif(N,0.4,0.5) # leg as proportion of height
leg_left <- leg_prop*height + # sim left leg as proportion + error
rnorm( N , 0 , 0.02 )
leg_right <- leg_prop*height + # sim right leg as proportion + error
rnorm( N , 0 , 0.02 )
# combine into data frame
d <- data.frame(height,leg_left,leg_right)
m6.1 <- quap(
alist(
height ~ dnorm( mu , sigma ) ,
mu <- a + bl*leg_left + br*leg_right ,
a ~ dnorm( 10 , 100 ) ,
bl ~ dnorm( 2 , 10 ) ,
br ~ dnorm( 2 , 10 ) ,
sigma ~ dexp( 1 )
) , data=d )
precis(m6.1)
##Learning quadratic approximation##############
library(rethinking)
m6.1 <- quap(
alist(
height ~ dnorm( mu , sigma ) ,
mu <- a + bl*leg_left + br*leg_right ,
a ~ dnorm( 10 , 100 ) ,
bl ~ dnorm( 2 , 10 ) ,
br ~ dnorm( 2 , 10 ) ,
sigma ~ dexp( 1 )
) , data=d )
precis(m6.1)
post <- extract.samples(m6.1)
plot( bl ~ br , post , col=col.alpha(rangi2,0.1) , pch=16 )
sum_blbr <- post$bl + post$br
dens( sum_blbr , col=rangi2 , lwd=2 , xlab="sum of bl and br" )
m6.2 <- quap(
alist(
height ~ dnorm( mu , sigma ) ,
mu <- a + bl*leg_left,
a ~ dnorm( 10 , 100 ) ,
bl ~ dnorm( 2 , 10 ) ,
sigma ~ dexp( 1 )
) , data=d )
precis(m6.2)
data(milk)
d <- milk
d$K <- standardize( d$kcal.per.g )
d$F <- standardize( d$perc.fat )
d$L <- standardize( d$perc.lactose )
m6.3 <- quap(
alist(
K ~ dnorm( mu , sigma ) ,
mu <- a + bF*F ,
a ~ dnorm( 0 , 0.2 ) ,
bF ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) , data=d )
# kcal.per.g regressed on perc.lactose
m6.4 <- quap(
alist(
K ~ dnorm( mu , sigma ) ,
mu <- a + bL*L ,
a ~ dnorm( 0 , 0.2 ) ,
bL ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) , data=d )
precis( m6.3 )
precis( m6.4 )
m6.5 <- quap(
alist(
K ~ dnorm( mu , sigma ) ,
mu <- a + bF*F + bL*L ,
a ~ dnorm( 0 , 0.2 ) ,
bF ~ dnorm( 0 , 0.5 ) ,
bL ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) ,
data=d )
precis( m6.5 )
pairs( ~ kcal.per.g + perc.fat + perc.lactose , data=d , col=rangi2 )
set.seed(71)
# number of plants
N <- 100
# simulate initial heights
h0 <- rnorm(N,10,2)
# assign treatments and simulate fungus and growth
treatment <- rep( 0:1 , each=N/2 )
fungus <- rbinom( N , size=1 , prob=0.5 - treatment*0.4 )
h1 <- h0 + rnorm(N, 5 - 3*fungus)
# compose a clean data frame
d <- data.frame( h0=h0 , h1=h1 , treatment=treatment , fungus=fungus )
sim_p <- rlnorm( 1e4 , 0 , 0.25 )
precis( data.frame(sim_p) )
sim_p <- rlnorm( 1e4 , 0 , 0.25 )
precis( data.frame(sim_p) )
m6.6 <- quap(
alist(
h1 ~ dnorm( mu , sigma ),
mu <- h0*p,
p ~ dlnorm( 0 , 0.25 ),
sigma ~ dexp( 1 )
), data=d )
precis(m6.6)
m6.7 <- quap(
alist(
h1 ~ dnorm( mu , sigma ),
mu <- h0 * p,
p <- a + bt*treatment + bf*fungus,
a ~ dlnorm( 0 , 0.2 ) ,
bt ~ dnorm( 0 , 0.5 ),
bf ~ dnorm( 0 , 0.5 ),
sigma ~ dexp( 1 )
), data=d )
precis(m6.7)
m6.8 <- quap(
alist(
h1 ~ dnorm( mu , sigma ),
mu <- h0 * p,
p <- a + bt*treatment,
a ~ dlnorm( 0 , 0.2 ),
bt ~ dnorm( 0 , 0.5 ),
sigma ~ dexp( 1 )
), data=d )
precis(m6.8)
library(dagitty)
plant_dag <- dagitty( "dag {
H_0 -> H_1
F -> H_1
T -> F
}")
coordinates( plant_dag ) <- list( x=c(H_0=0,T=2,F=1.5,H_1=1) ,
y=c(H_0=0,T=0,F=0,H_1=0) )
drawdag( plant_dag )
impliedConditionalIndependencies(plant_dag)
set.seed(71)
N <- 1000
h0 <- rnorm(N,10,2)
treatment <- rep( 0:1 , each=N/2 )
M <- rbern(N)
fungus <- rbinom( N , size=1 , prob=0.5 - treatment*0.4 + 0.4*M )
h1 <- h0 + rnorm( N , 5 + 3*M )
d2 <- data.frame( h0=h0 , h1=h1 , treatment=treatment , fungus=fungus )
library(rethinking)
d <- sim_happiness( seed=1977 , N_years=1000 )
precis(d)
d2 <- d[ d$age>17 , ] # only adults
d2$A <- ( d2$age - 18 ) / ( 65 - 18 )
d2$mid <- d2$married + 1
m6.9 <- quap(
alist(
happiness ~ dnorm( mu , sigma ),
mu <- a[mid] + bA*A,
a[mid] ~ dnorm( 0 , 1 ),
bA ~ dnorm( 0 , 2 ),
sigma ~ dexp(1)
) , data=d2 )
precis(m6.9,depth=2)
m6.10 <- quap(
alist(
happiness ~ dnorm( mu , sigma ),
mu <- a + bA*A,
a ~ dnorm( 0 , 1 ),
bA ~ dnorm( 0 , 2 ),
sigma ~ dexp(1)
) , data=d2 )
precis(m6.10)
N <- 200 # number of grandparent-parent-child triads
b_GP <- 1 # direct effect of G on P
b_GC <- 0 # direct effect of G on C
b_PC <- 1 # direct effect of P on C
b_U <- 2 # direct effect of U on P and C
set.seed(1)
U <- 2*rbern( N , 0.5 ) - 1
G <- rnorm( N )
P <- rnorm( N , b_GP*G + b_U*U )
C <- rnorm( N , b_PC*P + b_GC*G + b_U*U )
d <- data.frame( C=C , P=P , G=G , U=U )
m6.11 <- quap(
alist(
C ~ dnorm( mu , sigma ),
mu <- a + b_PC*P + b_GC*G,
a ~ dnorm( 0 , 1 ),
c(b_PC,b_GC) ~ dnorm( 0 , 1 ),
sigma ~ dexp( 1 )
), data=d )
precis(m6.11)
m6.12 <- quap(
alist(
C ~ dnorm( mu , sigma ),
mu <- a + b_PC*P + b_GC*G + b_U*U,
a ~ dnorm( 0 , 1 ),
c(b_PC,b_GC,b_U) ~ dnorm( 0 , 1 ),
sigma ~ dexp( 1 )
), data=d )
precis(m6.12)
library(dagitty)
dag_6.1 <- dagitty( "dag {
U [unobserved]
X -> Y
X <- U <- A -> C -> Y
U -> B <- C
}")
adjustmentSets( dag_6.1 , exposure="X" , outcome="Y" )
data<-read.csv("Data/shortlist_data_0813.csv")
library(ggplot2)
library(stringr)
library(tidyverse)
library(viridis)
my.theme<-theme(axis.title = element_text(size=12),
legend.title=element_text(size=12),
legend.text = element_text(size=10))
lst.data<-read.csv("Data/compiled_data_0813.csv")
setwd("~/Masters/Maps and Data/urban_sprawl_stats")
lst.data<-read.csv("Data/compiled_data_0813.csv")
#install.packages("qpcR")
library(qpcR)
values<-AIC(lst.model, lst.model2)
akaike.weights(values)$weights
#First attempt model
lst.model<-lm(LST_mean~BD+X.canopy+log(Income)+log(river.distance..meters.)+Imp2, data=lst.data)
#canopy cover and impervious seem a little correlated, same with BD and impervious
#I'm testing a model that removes impervious cover for that reason
lst.model2<-lm(LST_mean~BD+X.canopy+Income+river.distance..meters., data=lst.data)
values<-AIC(lst.model, lst.model2)
akaike.weights(values)$weights
values<-AIC(lst.model)
akaike.weights(values)$weights
?akaike,weights
?akaike.weights
akaike.weights(values)
values<-AIC(lst.model, lst.model2)
akaike.weights(values)
AIC(lst.model)
AIC(lst.model2)
akaike.weights(lst.model)
akaike.weights(values)
0.377/0.622
values<-AIC(no2.gam10, no2.gam11)
no2.data<-read.csv("Data/compiled_data_0813.csv")
##Testing GAM models
library(mgcv)
no2.gam<-gam(NO2_mean~s(BD)+s(X.canopy)+s(Income)+s(Imp.)+s(petrochem_distance)+
s(road.distance..meters.)+s(Road.), data=no2.data, method="REML")
summary(no2.gam)
gam.check(no2.gam)
no2.gam2<-gam(NO2_mean~s(BD)+s(X.canopy)+s(Imp.)+s(petrochem_distance)+s(Income)+
s(road.distance..meters.)+s(Road.)+ti(petrochem_distance, Income), data=no2.data, method="REML")
summary(no2.gam2)
#interaction term not very significant
no2.gam3<-gam(NO2_mean~s(BD)+s(X.canopy)+s (Imp.)+s(petrochem_distance)+s(Income)+
s(road.distance..meters.)+s(Road.)+
ti(X.canopy, Imp.), data=no2.data, method="REML")
summary(no2.gam3)
#interaction between imp. and canopy seems less important
no2.gam.x<-gam(NO2_mean~s(BD)+s(X.canopy)+s (Imp.)+s(petrochem_distance)+s(Income)+
s(road.distance..meters.)+s(Road.)+
ti(X.canopy, BD), data=no2.data, method="REML")
summary(no2.gam.x)
#interaction between BD and canopy seems less important
anova(no2.gam,no2.gam2,no2.gam3, test="Chisq")
anova(no2.gam, no2.gam2, test="Chisq")
anova(no2.gam, no2.gam3, test="Chisq")
#appears that model with no interactions is best so far.
##trying removing variables
no2.gam4<-gam(NO2_mean~s(BD)+s(X.canopy)+s(Income)+s(Imp.)+s(petrochem_distance)+
s(Road.), data=no2.data, method="REML")
summary(no2.gam4)
anova(no2.gam, no2.gam4, test="Chisq")
AIC(no2.gam)
AIC(no2.gam4)
#more complex model is better
no2.gam5<-gam(NO2_mean~s(BD)+s(X.canopy)+s(Income)+s(Imp.)+s(petrochem_distance)+
s(road.distance..meters.), data=no2.data, method="REML")
anova(no2.gam,no2.gam4, no2.gam5, test="Chisq")
anova(no2.gam, no2.gam4, test="Chisq")
anova(no2.gam, no2.gam5, test="Chisq")
AIC(no2.gam5)
#model no2.gam and no2.gam5 are the same AIC so I'll choose the simpler one.
no2.gam6<-gam(NO2_mean~s(BD)+s(X.canopy)+s(Income)+s(petrochem_distance)+
s(road.distance..meters.), data=no2.data, method="REML")
anova(no2.gam,no2.gam4, no2.gam6, test="Chisq")
anova(no2.gam5, no2.gam6, test="Chisq")
AIC(no2.gam5)
AIC(no2.gam6)
#model that excludes imp. seems stronger
no2.gam7<-gam(NO2_mean~s(BD)+s(Income)+s(petrochem_distance)+
s(road.distance..meters.), data=no2.data, method="REML")
anova(no2.gam, no2.gam6, no2.gam7, test="Chisq")
anova(no2.gam6, no2.gam7, test="Chisq")
AIC(no2.gam6)
AIC(no2.gam7)
#model excluding canopy cover is slightly stronger but based on the literature I
#think it's important to include
#no2.gam6 seems to be the winner so far
gam.check(no2.gam6)
concurvity(no2.gam6, full=TRUE)
vis.gam(no2.gam6, view=c("petrochem_distance", "Income"), color="heat", plot.type="persp",
theta=140)
library(nlme)
library(gstat)
library(sp)
library(ape)
##checking for spatial autocorrelation
no2.modelspace<-gam(NO2_mean~s(BD)+s(petrochem_distance)+s(X.canopy)+
s(road.distance..meters.), data=no2.data, method="REML")
coordinates(no2.data)<-c('Long','Lat')
resids<-residuals(no2.modelspace)
no2.data$resids=resids
bubble(no2.data,zcol='resids')
V<-variogram(resids~1, data=no2.data)
plot(V, pch=16, col="black")
#looks like definite spatial autocorrelation
test.dists <- as.matrix(dist(cbind(no2.data$Long, no2.data$Lat)))
test.dists.inv <- 1/test.dists
diag(test.dists.inv) <- 0
test.dists.inv[1:5, 1:5]
test.dists.inv[is.infinite(test.dists.inv)] <- 0
Moran.I(no2.data$resids, test.dists.inv)
#Moran's I seems to confirm this
#will have to account for spatial autocorrelation in the model
coords<-coordinates(no2.data)
no2.gam8<-gam(NO2_mean~s(BD)+s(Income)+s(petrochem_distance)+s(X.canopy)+
s(road.distance..meters.)+s(Lat,Long), data=no2.data, method="REML")
summary(no2.gam8)
gam.check(no2.gam8)
concurvity(no2.gam8)
#distance and coords have high concurvity
no2.gam9<-gam(NO2_mean~s(BD)+s(Income)+s(X.canopy)+
s(road.distance..meters.)+s(Lat,Long), data=no2.data, method="REML")
summary(no2.gam9)
gam.check(no2.gam9)
concurvity(no2.gam9)
#this model gets rid of concurvity
anova(no2.gam9, no2.gam8, test="Chisq")
AIC(no2.gam9)
AIC(no2.gam8)
AIC(no2.gam7)
##model 8 has lowest AIC but it has concurvity close to 100% so I don't think it's appropriate
#to include both
no2.gam10<-gam(NO2_mean~s(BD)+s(Income)+s(road.distance..meters.)+
s(Lat,Long, k=65), data=no2.data, method="REML")
gam.check(no2.gam10)
summary(no2.gam10)
plot(no2.gam10, scheme=2, page=1)
##trying spatial plus approach
BD_gam<- gam(BD~s(Lat*Long), data=no2.data)
resid_BD<-residuals(BD_gam)
income_gam<-gam(log(Income)~s(Lat*Long), data=no2.data, na.action=na.exclude)
resid_income<-residuals(income_gam)
road_gam<-gam(log(road.distance..meters.)~s(Lat*Long), data=no2.data)
resid_road<-residuals(road_gam)
canopy_gam<-gam(X.canopy~s(Lat*Long), data=no2.data)
resid_canopy<-residuals(canopy_gam)
no2.gam11<-gam(NO2_mean~resid_BD+resid_income+resid_road+resid_canopy+s(Lat,Long), data=no2.data,
method="REML")
summary(no2.gam11)
gam.check(no2.gam11)
plot(no2.gam11, scheme=2, page=1)
concurvity(no2.gam11)
vis.gam(no2.gam10, view=c("Income","road.distance..meters."),
plot.type="persp", theta=1, xlab="Income",
ylab="Distance to Major Road", zlab="NO2 Concentration")
Boroughs<-as.factor(no2.data$Borough)
plot(NO2_mean~Income, data=no2.data)
abline(lm)
lm<-lm(NO2_mean~log(Income), data=no2.data)
##tring borough as random effect
no2.gam12<-gam(NO2_mean~s(BD)+s(Income)+s(road.distance..meters.)+s(X.canopy)+
s(Boroughs, bs="re"), data=no2.data, method="REML", na.action=na.exclude)
summary(no2.gam12)
##trying both approaches together
no2.gam13<-gam(NO2_mean~resid_BD+resid_income+resid_road+resid_canopy
+s(Lat,Long)+s(Boroughs, bs="re"), data=no2.data,
method="REML")
summary(no2.gam13)
##spatial+ model without borough random effect is best
View(no2.data)
fil<-filter(no2.data, Households>0)
plot(NO2_mean~Households, data=fil)
lm1<-lm(NO2_mean~Households, data=fil)
abline(lm1)
summary(lm1)
plot(LST_mean~Households, data=fil, ylab="Land Surface Temperature (C)", xlab="Number of Households",
pch=16)
lm2<-lm(LST_mean~Households, data=no2.fil)
abline(lm2)
summary(lm2)
##Looking at alternative dates
no2.alt<-read.csv("Data/NO2_alternativedates.csv")
BD_gam<- gam(BD~s(Lat*Long), data=no2.alt)
resid_BD<-residuals(BD_gam)
income_gam<-gam(log(Income)~s(Lat*Long), data=no2.alt, na.action=na.exclude)
resid_income<-residuals(income_gam)
road_gam<-gam(log(road.distance..meters.)~s(Lat*Long), data=no2.alt)
resid_road<-residuals(road_gam)
canopy_gam<-gam(X.canopy~s(Lat*Long), data=no2.alt)
resid_canopy<-residuals(canopy_gam)
no2.gamalt<-gam(MayNO2_mean~resid_BD+resid_income+resid_road+resid_canopy+s(Lat,Long), data=no2.alt,
method="REML")
summary(no2.gamalt)
summary(no2.gam11)
plot(NO2_mean~BD, data=no2.alt, xlab="% Building Density", ylab="July NO2 Concentration", pch=16)
ab<-(lm(OctNO2_mean~BD, data=no2.alt))
summary(ab)
plot(MayNO2_mean~BD, data=no2.alt,  xlab="% Building Density", ylab="May NO2 Concentration", pch=16)
plot(OctNO2_mean~BD, data=no2.alt,  xlab="% Building Density", ylab=" October NO2 Concentration", pch=16)
vis.gam(no2.gam11, view=c("resid_road", "resid_income"), plot.type="persp")
plot(NO2_mean~Households, data=no2.data)
lm1<-lm(NO2_mean~Households, data=no2.data)
abline(lm1)
summary(lm1)
##households as GAM
House_gam<- gam(Households~s(Lat*Long), data=fil)
resid_House<-residuals(House_gam)
no2.gam.house<-gam(NO2_mean~s(resid_House)+s(Lat,Long), data=fil,
method="REML")
summary(no2.gam.house)
gam.check(no2.gam.house)
##AIC weights
library(qpcR)
values<-AIC(no2.gam10, no2.gam11)
akaike.weights(values)
values<-AIC(no2.gam12, no2.gam11)
akaike.weights(values)
values
akaike.weights(values)
BIC(no2.gam12, no2.gam11)
